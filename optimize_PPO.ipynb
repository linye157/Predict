{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载标准化数据和scaler模型\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "import shap\n",
    "from mlutils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置类\n",
    "class Config:\n",
    "    # 目标性能阈值（根据需求修改）\n",
    "    TARGETS = np.array([134, 278, 22.5])  # 三个性能指标的最低要求\n",
    "    # SHAP参数\n",
    "    SAMPLE_RATIO = 0.1     # 背景数据采样比例\n",
    "    N_SUMMARY = 100        # SHAP背景数据压缩量\n",
    "    TOP_K = 5              # 每个样本选择的关键参数数量\n",
    "\n",
    "    MAX_STEPS = 100  # 最大步数\n",
    "    BUFFER_RATIO = 0.1  # 动态范围比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 识别不合格样本\n",
    "def find_unqualified_samples(y,  tragets):\n",
    "    \"\"\"找到至少有一个性能指标不达标的样本\"\"\"\n",
    "    unqualified_mask = np.any(y < tragets, axis=1)\n",
    "    return np.where(unqualified_mask)[0]\n",
    "\n",
    "# 判断力学性能是否达标（用户自定义）\n",
    "def is_satisfied(y_pred,  tragets):\n",
    "    # 示例：假设 y_pred 是 3 个力学性能值，targets 是达标指标\n",
    "    return all(y >= t for y, t in zip(y_pred, tragets))\n",
    "\n",
    "#反标准化函数\n",
    "def inverse_normalize(sample,scaler):\n",
    "    inverse_sample=scaler.inverse_transform(sample.reshape(1,-1))\n",
    "    return inverse_sample[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Procedure_header=['化学元素含量', '化学元素含量', '化学元素含量', '化学元素含量', '化学元素含量', '化学元素含量', '化学元素含量', '化学元素含量', '化学元素含量', \n",
    "                  '热轧', '热轧', '热轧', '热轧', '热轧', '热轧', '热轧', '热轧', \n",
    "                  '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', \n",
    "                  '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', \n",
    "                  '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧', '冷轧',\n",
    "                  '镀锌', '镀锌', '镀锌', '镀锌', '镀锌', '镀锌', '镀锌', '镀锌', '镀锌', '镀锌', '镀锌', '镀锌', '镀锌', '镀锌']\n",
    "Parameter_header = [\n",
    "    \"碳\", \"硅\", \"锰\", \"磷\", \"硫\", \"钛\", \"铌\", \"氧\", \"氮\", \"材料实际重量\", \"出口材料实际厚度\",\n",
    "    \"出口材料实际宽度\", \"卷取温度平均值\", \"出炉温度\", \"在炉时间\", \"精轧入口平均温度\", \"精轧出口平均温度\",\n",
    "    \"出口材料实际厚度公差\", \"出口材料实际宽度公差\", \"出口材料实际重量\", \"入口材料1厚度\", \"入口材料1宽度\",\n",
    "    \"入口材料1重量\", \"S1机架压下率\", \"S2机架压下率\", \"S3机架压下率\", \"S4机架压下率\", \"S5机架压下率\",\n",
    "    \"S1机架入口张力\", \"S1~S2机架间张力\", \"S2～S3机架间张力\", \"S3～S4机架间张力\", \"S4～S5机架间张力\",\n",
    "    \"S5出口张力\", \"S1机架入口单位张力\", \"S1~S2机架间单位张力\", \"S2~S3机架间单位张力\",\n",
    "    \"S3~S4机架间单位张力\", \"S4~S5机架间单位张力\", \"S5机架工作轧辊粗糙度(底)\", \"S5机架工作轧辊粗糙度(上)\",\n",
    "    \"1#机架轧制力模型设定值\", \"2#机架轧制力模型设定值\", \"3#机架轧制力模型设定值\", \"4#机架轧制力模型设定值\",\n",
    "    \"5#机架轧制力模型设定值\", \"拉矫率平均值\", \"1#酸槽温度\", \"2#酸槽温度\", \"3#酸槽温度\", \"酸洗工序速度平均值1\",\n",
    "    \"上表面镀层重量\", \"下表面镀层重量\", \"平整率平均值\", \"上表面涂油量\", \"下表面涂油量\", \"工艺段速度平均值\",\n",
    "    \"ES平均温度\", \"FCS平均温度\", \"IHS平均温度\", \"SCS平均温度\", \"SF平均温度\", \"RCS平均温度\",\n",
    "    \"RTF平均温度\", \"JPF平均温度\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x,test_y=x_y_split(test_data_path, scaler=joblib.load(scaler_model_path))\n",
    "train_x,train_y=x_y_split(train_data_path, scaler=joblib.load(scaler_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Random Forest'\n",
    "model=models[model_name]\n",
    "model=joblib.load(pre_model_path + model_name + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机提取train_x的0.1倍样本\n",
    "train_x_sample=train_x[np.random.choice(train_x.shape[0], int(train_x.shape[0]*0.1), replace=False)]\n",
    "train_x_sample_summary = shap.sample(train_x_sample, 100)\n",
    "#使用shap的kernel explainer对混合模型\n",
    "explainer = shap.KernelExplainer(model.predict, train_x_sample_summary)\n",
    "def cal_shap_values(x):\n",
    "    return explainer.shap_values(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_param_bounds(sample, X_data, top_indices, buffer_ratio):\n",
    "    \"\"\"\n",
    "    作用：根据历史数据和当前样本生成优化参数范围\n",
    "    sample: 当前样本\n",
    "    X_data: 历史数据\n",
    "    top_indices: 优化参数索引\n",
    "    buffer——ratio: 动态范围比例\n",
    "    \"\"\"\n",
    "    bounds = {}\n",
    "    for idx in top_indices:\n",
    "        # 全局数据范围（考虑工艺限制）\n",
    "        global_min = X_data[:, idx].min()\n",
    "        global_max = X_data[:, idx].max()\n",
    "        \n",
    "        # 当前值\n",
    "        current_val = sample[idx]\n",
    "        \n",
    "        # 动态范围：当前值±buffer_ratio范围的全局裁剪\n",
    "        buffer_range = (global_max - global_min) * buffer_ratio\n",
    "        min_val = max(global_min, current_val - buffer_range)\n",
    "        max_val = min(global_max, current_val + buffer_range)\n",
    "        \n",
    "        bounds[f'x{idx}'] = (min_val, max_val)\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义环境\n",
    "class ParamOptimizationEnv(gym.Env):\n",
    "    def __init__(self, sample, top_indices, bounds, model, is_satisfied):\n",
    "        super(ParamOptimizationEnv, self).__init__()\n",
    "        self.sample = sample.copy()  # 初始工艺参数\n",
    "        self.top_indices = top_indices  # 需要优化的参数索引\n",
    "        self.bounds = bounds  # 优化范围\n",
    "        self.model = model  # 预测模型\n",
    "        self.is_satisfied = is_satisfied  # 达标判断函数\n",
    "        self.current_params = sample.copy()\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(top_indices),), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(len(top_indices),), dtype=np.float32)\n",
    "        self.max_steps = Config.MAX_STEPS\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_params = self.sample.copy()\n",
    "        self.current_step = 0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def step(self, action):\n",
    "        # 更新需要优化的参数\n",
    "        for i, idx in enumerate(self.top_indices):\n",
    "            delta = action[i] * (self.bounds[f'x{idx}'][1] - self.bounds[f'x{idx}'][0]) / 2\n",
    "            self.current_params[idx] += delta\n",
    "            self.current_params[idx] = np.clip(self.current_params[idx], self.bounds[f'x{idx}'][0], self.bounds[f'x{idx}'][1])\n",
    "\n",
    "        # 预测力学性能\n",
    "        y_pred = self.model.predict(self.current_params.reshape(1, -1))[0]\n",
    "        satisfied = self.is_satisfied(y_pred, Config.TARGETS)\n",
    "        \n",
    "        # 奖励设计\n",
    "        if satisfied:\n",
    "            reward = 10  # 达标时高奖励\n",
    "        else:\n",
    "            # 未达标时奖励与目标距离负相关\n",
    "            reward = -sum(abs(y - t) for y, t in zip(y_pred, [0.8, 0.9, 1.0])) / 3\n",
    "        reward -= 0.1  # 步数惩罚\n",
    "        \n",
    "        self.current_step += 1\n",
    "        done = satisfied or self.current_step >= self.max_steps\n",
    "        return self._get_obs(), reward, done, {\"y_pred\": y_pred}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return self.current_params[self.top_indices]\n",
    "\n",
    "# 主函数：优化单个样本\n",
    "def optimize_sample(sample, X_data, model,ppo_model=None):\n",
    "    # 计算 SHAP 值并选择 top_k 参数\n",
    "    shap_values = cal_shap_values(sample)\n",
    "    top_indices = np.argsort(np.abs(shap_values).mean(1))[::-1][:Config.TOP_K]\n",
    "    bounds = generate_param_bounds(sample, X_data, top_indices, Config.BUFFER_RATIO)\n",
    "\n",
    "    # 创建环境\n",
    "    env = ParamOptimizationEnv(sample, top_indices, bounds, model, is_satisfied)\n",
    "\n",
    "    # 训练 PPO 模型\n",
    "    ppo_model = PPO(\"MlpPolicy\", env, verbose=0, batch_size=256, n_epochs=10)\n",
    "    ppo_model.learn(total_timesteps=100)\n",
    "\n",
    "    # 测试优化\n",
    "    obs = env.reset()\n",
    "    for _ in range(Config.MAX_STEPS):\n",
    "        action, _ = ppo_model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            # print(f\"优化完成，调整后的力学性能: {info['y_pred']}\")\n",
    "            break\n",
    "    if is_satisfied(info['y_pred'], Config.TARGETS):\n",
    "        status='success'\n",
    "        opt_pred=info['y_pred']\n",
    "    else:\n",
    "        status='fail'\n",
    "        opt_pred=None\n",
    "    return env.current_params, top_indices, bounds, status, opt_pred\n",
    "# #示例调用\n",
    "unqualified_samples = find_unqualified_samples(test_y, Config.TARGETS)\n",
    "sample_idx = unqualified_samples[0]\n",
    "sample = test_x[sample_idx]\n",
    "print(f\"待优化样本索引: {sample_idx}\")\n",
    "optimized_params, top_indices, bounds, status,opt_pred = optimize_sample(sample, train_x_sample, model)\n",
    "print(f\"优化结果: {status}\")\n",
    "if status=='success':\n",
    "    print(f\"优化前的力学性能: {test_y[sample_idx]}\")\n",
    "    print(f\"优化后的力学性能: {opt_pred}\")\n",
    "\n",
    "    print('优化前的参数：')\n",
    "    print(inverse_normalize(sample,joblib.load(scaler_model_path)))\n",
    "    print('优化后的参数：')\n",
    "    print(inverse_normalize(optimized_params,joblib.load(scaler_model_path)))\n",
    "\n",
    "else:\n",
    "    print(f\"优化失败\")\n",
    "    print(f\"优化前的力学性能: {test_y[sample_idx]}\")\n",
    "    print(f\"优化后的力学性能: {opt_pred}\")\n",
    "    print('优化前的参数：')\n",
    "    print(inverse_normalize(sample,joblib.load(scaler_model_path)))\n",
    "    print('优化后的参数：')\n",
    "    print(inverse_normalize(optimized_params,joblib.load(scaler_model_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_many(test_x, test_y, X_data, model):\n",
    "        #找到不合格样本\n",
    "    unqualified_samples = find_unqualified_samples(test_y, Config.TARGETS)\n",
    "    results = []\n",
    "    # i=0\n",
    "    for idx in tqdm(unqualified_samples):\n",
    "        \n",
    "        # i=i+1\n",
    "\n",
    "        ori_sample = test_x[idx]\n",
    "        ori_pred=test_y[idx]\n",
    "        optimized_params, top_indices, bounds, status,opt_pred = optimize_sample(ori_sample, X_data, model)\n",
    "        #对工艺参数进行反标准化\n",
    "        ori_sample=inverse_normalize(ori_sample,scaler)\n",
    "        optimized_params=inverse_normalize(optimized_params,scaler)\n",
    "        #记录结果\n",
    "        if status=='success':\n",
    "            param_changes=[]\n",
    "            for p_idx in top_indices:\n",
    "                ori_val=ori_sample[p_idx]\n",
    "                opt_val=optimized_params[p_idx]\n",
    "                change_pct=(opt_val-ori_val)/ori_val*100\n",
    "                param_changes.append({\n",
    "                    'param_idx':int(p_idx),\n",
    "                    'param_name':Procedure_header[int(p_idx)]+'过程的'+Parameter_header[int(p_idx)],\n",
    "                    'ori_val':float(ori_val),\n",
    "                    'opt_val':float(opt_val),\n",
    "                    'change_pct':float(change_pct)\n",
    "                \n",
    "                })\n",
    "            #把ori_pred和opt_pred转换为列表\n",
    "            if hasattr(ori_pred,'tolist'):\n",
    "                ori_pred=ori_pred.tolist()\n",
    "            else:\n",
    "                ori_pred=list(ori_pred)\n",
    "            if hasattr(opt_pred,'tolist'):\n",
    "                opt_pred=opt_pred.tolist()\n",
    "            else:\n",
    "                opt_pred=list(opt_pred)\n",
    "            \n",
    "            results.append({\n",
    "                'sample_id':int(idx),\n",
    "                'status':status,\n",
    "                'original_performance':ori_pred,\n",
    "                'optimized_performance':opt_pred,\n",
    "                'param_changes':param_changes,\n",
    "                'top_params_index':[int(p_idx) for p_idx in top_indices.tolist()],\n",
    "                'top_paras':[Parameter_header[int(pidx)] for pidx in top_indices.tolist()]\n",
    "            })\n",
    "        \n",
    "        else:\n",
    "            results.append({\n",
    "                'sample_id':int(idx),\n",
    "                'status':status,\n",
    "                'original_performance':ori_pred,\n",
    "                'optimized_performance':None,\n",
    "                'param_changes':None,\n",
    "                'top_params_index':[int(p_idx) for p_idx in top_indices.tolist()],\n",
    "                'top_paras':[Parameter_header[int(pidx)] for pidx in top_indices.tolist()]\n",
    "            })\n",
    "\n",
    "        # if i==4:\n",
    "        #     break\n",
    "        \n",
    "    df_results=pd.DataFrame(results)\n",
    "    success_rate=(df_results['status'] == 'success').mean()\n",
    "    print(f\"\\n优化完成！成功率：{success_rate:.1%}\")\n",
    "    # 保存到CSV（示例），编码为UTF-8\n",
    "    df_results.to_csv('results_PPO.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n100%|██████████| 408/408 [3:54:54<00:00, 34.54s/it]  \\n\\n优化完成！成功率：99.3%\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_many(test_x, test_y, train_x_sample, model)\n",
    "\"\"\"\n",
    "100%|██████████| 408/408 [3:54:54<00:00, 34.54s/it]  \n",
    "\n",
    "优化完成！成功率：99.3%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# from contextlib import redirect_stdout\n",
    "# PPO_model_path='./model/pretrained_ppo.zip'\n",
    "# def optimize_many(test_x, test_y, X_data, model):\n",
    "#     # 找到不合格样本\n",
    "#     unqualified_samples = find_unqualified_samples(test_y, Config.TARGETS)\n",
    "    \n",
    "#     #不存在预训练模型\n",
    "#     if not os.path.exists(PPO_model_path):\n",
    "#         # 1. 选择预训练样本（例如 10% 的未达标样本）\n",
    "#         print(\"未找到预训练模型，开始训练...\")\n",
    "#         pretrain_size = max(1, int(0.1 * len(unqualified_samples)))  # 至少选择 1 个样本\n",
    "#         pretrain_indices = np.random.choice(unqualified_samples, size=pretrain_size, replace=False)\n",
    "        \n",
    "#         # 2. 创建预训练环境 - 先计算 top_indices 和 bounds\n",
    "#         pretrain_envs = []\n",
    "#         for idx in pretrain_indices:\n",
    "#             sample = test_x[idx]\n",
    "#             shap_values = cal_shap_values(sample)\n",
    "#             top_indices = np.argsort(np.abs(shap_values).mean(1))[::-1][:Config.TOP_K]\n",
    "#             bounds = generate_param_bounds(sample, X_data, top_indices, Config.BUFFER_RATIO)\n",
    "#             env = ParamOptimizationEnv(sample, top_indices, bounds, model, is_satisfied)\n",
    "#             pretrain_envs.append(env)\n",
    "        \n",
    "#         vec_env = DummyVecEnv([lambda env=env: env for env in pretrain_envs])  # 使用参数捕获防止延迟绑定\n",
    "        \n",
    "#         # 3. 训练预训练模型\n",
    "#         pretrained_ppo = PPO(\"MlpPolicy\", vec_env, verbose=0, batch_size=256, n_epochs=10)\n",
    "#         pretrained_ppo.learn(total_timesteps=1000)  # 训练通用模型\n",
    "#         pretrained_ppo.save(PPO_model_path)     # 保存模型\n",
    "    \n",
    "#     print(\"开始优化未达标样本...\")\n",
    "#     # 4. 对所有未达标样本进行优化\n",
    "#     results = []\n",
    "#     for idx in tqdm(unqualified_samples):\n",
    "#         ori_sample = test_x[idx]\n",
    "#         ori_pred = test_y[idx]\n",
    "        \n",
    "#         # 计算 SHAP 值并选择 top_k 参数\n",
    "#         shap_values = cal_shap_values(ori_sample)\n",
    "#         top_indices = np.argsort(np.abs(shap_values).mean(1))[::-1][:Config.TOP_K]\n",
    "#         bounds = generate_param_bounds(ori_sample, X_data, top_indices, Config.BUFFER_RATIO)\n",
    "        \n",
    "#         # 创建当前样本的环境\n",
    "#         env = ParamOptimizationEnv(ori_sample, top_indices, bounds, model, is_satisfied)\n",
    "#         # 加载预训练模型并微调，屏蔽输出\n",
    "#         with open(os.devnull, 'w') as f:\n",
    "#             with redirect_stdout(f):\n",
    "#                 ppo_model = PPO.load(PPO_model_path, env=env, verbose=0)\n",
    "#         ppo_model.learn(total_timesteps=1000)  # 微调，时间步远少于从头训练\n",
    "        \n",
    "#         # 测试优化\n",
    "#         obs = env.reset()\n",
    "#         for _ in range(Config.MAX_STEPS):\n",
    "#             action, _ = ppo_model.predict(obs)\n",
    "#             obs, reward, done, info = env.step(action)\n",
    "#             if done:\n",
    "#                 break\n",
    "        \n",
    "#         # 判断优化结果\n",
    "#         if is_satisfied(info['y_pred'], Config.TARGETS):\n",
    "#             status = 'success'\n",
    "#             opt_pred = info['y_pred']\n",
    "#         else:\n",
    "#             status = 'fail'\n",
    "#             opt_pred = None\n",
    "#         optimized_params = env.current_params\n",
    "        \n",
    "#         # 反标准化工艺参数\n",
    "#         ori_sample = inverse_normalize(ori_sample, scaler)\n",
    "#         optimized_params = inverse_normalize(optimized_params, scaler)\n",
    "        \n",
    "#         # 记录结果\n",
    "#         if status == 'success':\n",
    "#             param_changes = []\n",
    "#             for p_idx in top_indices:\n",
    "#                 ori_val = ori_sample[p_idx]\n",
    "#                 opt_val = optimized_params[p_idx]\n",
    "#                 change_pct = (opt_val - ori_val) / ori_val * 100\n",
    "#                 param_changes.append({\n",
    "#                     'param_idx': int(p_idx),\n",
    "#                     'param_name': Procedure_header[int(p_idx)] + '过程的' + Parameter_header[int(p_idx)],\n",
    "#                     'ori_val': float(ori_val),\n",
    "#                     'opt_val': float(opt_val),\n",
    "#                     'change_pct': float(change_pct)\n",
    "#                 })\n",
    "            \n",
    "#             # 转换为列表\n",
    "#             ori_pred = ori_pred.tolist() if hasattr(ori_pred, 'tolist') else list(ori_pred)\n",
    "#             opt_pred = opt_pred.tolist() if hasattr(opt_pred, 'tolist') else list(opt_pred)\n",
    "            \n",
    "#             results.append({\n",
    "#                 'sample_id': int(idx),\n",
    "#                 'status': status,\n",
    "#                 'original_performance': ori_pred,\n",
    "#                 'optimized_performance': opt_pred,\n",
    "#                 'param_changes': param_changes,\n",
    "#                 'top_params_index': [int(p_idx) for p_idx in top_indices.tolist()],\n",
    "#                 'top_paras': [Parameter_header[int(p_idx)] for p_idx in top_indices.tolist()]\n",
    "#             })\n",
    "#         else:\n",
    "#             results.append({\n",
    "#                 'sample_id': int(idx),\n",
    "#                 'status': status,\n",
    "#                 'original_performance': ori_pred,\n",
    "#                 'optimized_performance': None,\n",
    "#                 'param_changes': None,\n",
    "#                 'top_params_index': [int(p_idx) for p_idx in top_indices.tolist()],\n",
    "#                 'top_paras': [Parameter_header[int(p_idx)] for p_idx in top_indices.tolist()]\n",
    "#             })\n",
    "    \n",
    "#     # 5. 处理结果\n",
    "#     df_results = pd.DataFrame(results)\n",
    "#     success_rate = (df_results['status'] == 'success').mean()\n",
    "#     print(f\"\\n优化完成！成功率：{success_rate:.1%}\")\n",
    "#     df_results.to_csv('results_PPO.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "#     return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize_many(test_x, test_y, train_x_sample, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch121",
   "language": "python",
   "name": "pytorch121"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
